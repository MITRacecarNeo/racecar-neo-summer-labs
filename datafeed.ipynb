{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36fe682-525c-4f68-960e-634bc2a22f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time\n",
    "\n",
    "from pycoral.adapters.common import input_size\n",
    "from pycoral.adapters.detect import get_objects\n",
    "from pycoral.utils.dataset import read_label_file\n",
    "from pycoral.utils.edgetpu import make_interpreter\n",
    "from pycoral.utils.edgetpu import run_inference\n",
    "\n",
    "# Define paths to model and label directories\n",
    "default_path = 'models' # location of model weights and labels\n",
    "model_name = 'helov1_efficientdet0_edgetpu.tflite'\n",
    "label_name = 'ewasp_label.txt'\n",
    "\n",
    "model_path = default_path + \"/\" + model_name\n",
    "label_path = default_path + \"/\" + label_name\n",
    "\n",
    "# Define path for video to test model against\n",
    "video_path = \"data/20250409_1046MST.mp4\"\n",
    "\n",
    "# Define thresholds and number of classes to output\n",
    "SCORE_THRESH = 0.1\n",
    "NUM_CLASSES = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e63ea8-8926-4b64-8380-87bf7cbed0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that takes in a video and returns all the frames in a numpy array\n",
    "# path = a string that represents the absolute path of the video\n",
    "# start = (optional) starting frame to return, default 0\n",
    "# end = (optional) last frame to return, default -1 (last frame)\n",
    "def load_video(path, start=0, end=-1):\n",
    "    frames = []\n",
    "    count = 0\n",
    "    cap = cv2.VideoCapture(path)\n",
    "\n",
    "    # Catch edge case of video failure\n",
    "    if not cap.isOpened():\n",
    "        raise ValueError(f\"Error opening video!\")\n",
    "    \n",
    "    # Get video parameters\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Catch edge case of no end frame specified\n",
    "    if end == -1:\n",
    "        end = frame_count\n",
    "    \n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if count > start and count <= end:\n",
    "            frames.append(frame[:, :, 0].copy()) # only save the first channel for grayscale image\n",
    "        count += 1\n",
    "        \n",
    "    cap.release()\n",
    "    \n",
    "    # Fancy print details\n",
    "    print(f\"===== Video Details ======\")\n",
    "    print(f\"Video Length: {round((frame_count/fps)/60, 2)} min\")\n",
    "    print(f\"FPS: {fps}\")\n",
    "    print(f\"Frame Count: {frame_count}\")\n",
    "    print(f\"Frame Width: {frame_width}\")\n",
    "    print(f\"Frame Height: {frame_height}\")\n",
    "    print(f\"Frame Shape: {frames[0].shape}\")\n",
    "    print()\n",
    "          \n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268d9455-ec94-4e34-976b-e0c1741d706e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [FUNCTION] Modify image to label objs and score\n",
    "def append_objs_to_img(cv2_im, inference_size, objs, labels):\n",
    "    height, width = cv2_im.shape\n",
    "    scale_x, scale_y = width / inference_size[0], height / inference_size[1]\n",
    "    for obj in objs:\n",
    "        if obj.score > 0.1:\n",
    "            bbox = obj.bbox.scale(scale_x, scale_y)\n",
    "            x0, y0 = int(bbox.xmin), int(bbox.ymin)\n",
    "            x1, y1 = int(bbox.xmax), int(bbox.ymax)\n",
    "    \n",
    "            percent = int(100 * obj.score)\n",
    "            label = '{}% {}'.format(percent, labels.get(obj.id, obj.id))\n",
    "    \n",
    "            cv2_im = cv2.rectangle(cv2_im, (x0, y0), (x1, y1), (0, 255, 0), 2)\n",
    "            cv2_im = cv2.putText(cv2_im, label, (x0, y0+30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 0, 0), 2)\n",
    "    return cv2_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb90678-8963-4447-bb09-ab69067c8aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Dependencies\n",
    "import IPython\n",
    "import IPython.display\n",
    "from io import BytesIO\n",
    "import PIL.Image\n",
    "\n",
    "# [FUNCTION] Prepare .ipynb display\n",
    "def show_rgb_image_to_display(image_rgb, display):\n",
    "    \"\"\"\n",
    "    Displays a color image in the Jupyter Notebook.\n",
    "    Assumes image is in RGB format.\n",
    "    \"\"\"\n",
    "    io = BytesIO()\n",
    "    image = cv2.cvtColor(image_rgb, cv2.COLOR_BGR2RGB)\n",
    "    PIL.Image.fromarray(image).save(io, 'jpeg')\n",
    "    img_display = IPython.display.Image(data=io.getvalue())\n",
    "    display.update(img_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa39f338-e905-4ca4-8a87-357bff27b2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### FRAME EXTRACTION BLOCK ###\n",
    "\n",
    "fps = 60\n",
    "start = 25 # in seconds, multiply by fps before passing into video load function\n",
    "end = 90 # -1 represents end of video\n",
    "frames = load_video(video_path, start*fps, end*fps)\n",
    "\n",
    "# Print extracted footage details\n",
    "print(f\"===== Extracted Frame Details ======\")\n",
    "print(f\"Frame Count: {len(frames)}\")\n",
    "print(f\"Video Length: {round(len(frames)/fps/60, 2)} min\")\n",
    "print(f\"Frame Shape: {frames[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d85d8c-3fa4-42d1-97d8-e79045277949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The actual display\n",
    "display = IPython.display.display('', display_id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295ead7c-e94e-4d95-9ac9-fbf3ac37aafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: Load model and labels using pycoral.utils\n",
    "print('Loading {} with {} labels.'.format(model_path, label_path))\n",
    "interpreter = make_interpreter(model_path)\n",
    "interpreter.allocate_tensors()\n",
    "labels = read_label_file(label_path)\n",
    "inference_size = input_size(interpreter)\n",
    "\n",
    "# Loop through each frame and pass through model\n",
    "# Measure inference time for each pass\n",
    "inf_time = []\n",
    "for frame in frames:\n",
    "    # STEP 2: Preprocess image to the size and shape accepted by model\n",
    "    rgb_image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) # Needs to be 3-channel when fed into model\n",
    "    rgb_image = cv2.resize(rgb_image, inference_size)\n",
    "\n",
    "    time_cp1 = time.time()\n",
    "    # STEP 4: Let the model do the work\n",
    "    run_inference(interpreter, rgb_image.tobytes())\n",
    "    time_cp2 = time.time()\n",
    "    \n",
    "    # STEP 5: Get objects detected from the model\n",
    "    objs = get_objects(interpreter, SCORE_THRESH)[:NUM_CLASSES]\n",
    "\n",
    "    # STEP 6: Label detected objects to frame\n",
    "    image = append_objs_to_img(frame, inference_size, objs, labels)\n",
    "\n",
    "    # STEP 7: Show the image to the display\n",
    "    show_rgb_image_to_display(image, display)\n",
    "\n",
    "    # Calculate inference time and add to list\n",
    "    inf_time.append(round((time_cp2 - time_cp1)*1000, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f26c6e-16cb-4910-b34f-0ae4018dd813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Graph inference times as a line chart\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(inf_time, marker='o', linestyle='-')\n",
    "plt.title(\"Inference Time per Sample\")\n",
    "plt.xlabel(\"Sample Index\")\n",
    "plt.ylabel(\"Inference Time (ms)\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate average fps\n",
    "avg = 0\n",
    "for inf in inf_time:\n",
    "    avg += inf\n",
    "avg /= len(inf_time)\n",
    "print(f\"Average FPS: {1/(avg/1000)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ff7f12-c34e-41b7-aec9-f5c16d12af9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
