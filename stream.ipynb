{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725a6e06-8049-4ce0-81f1-c531698036ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time\n",
    "\n",
    "from pycoral.adapters.common import input_size\n",
    "from pycoral.adapters.detect import get_objects\n",
    "from pycoral.utils.dataset import read_label_file\n",
    "from pycoral.utils.edgetpu import make_interpreter\n",
    "from pycoral.utils.edgetpu import run_inference\n",
    "\n",
    "# Define paths to model and label directories\n",
    "default_path = 'models' # location of model weights and labels\n",
    "model_name = 'helov1_efficientdet0_edgetpu.tflite'\n",
    "label_name = 'ewasp_label.txt'\n",
    "\n",
    "model_path = default_path + \"/\" + model_name\n",
    "label_path = default_path + \"/\" + label_name\n",
    "\n",
    "# Define thresholds and number of classes to output\n",
    "SCORE_THRESH = 0.1\n",
    "NUM_CLASSES = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02bca51-3f07-4609-9648-d528ae5839ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [FUNCTION] Modify image to label objs and score\n",
    "def append_objs_to_img(cv2_im, inference_size, objs, labels):\n",
    "    height, width, channels = cv2_im.shape\n",
    "    scale_x, scale_y = width / inference_size[0], height / inference_size[1]\n",
    "    for obj in objs:\n",
    "        if obj.score > 0.5:\n",
    "            bbox = obj.bbox.scale(scale_x, scale_y)\n",
    "            x0, y0 = int(bbox.xmin), int(bbox.ymin)\n",
    "            x1, y1 = int(bbox.xmax), int(bbox.ymax)\n",
    "    \n",
    "            percent = int(100 * obj.score)\n",
    "            label = '{}% {}'.format(percent, labels.get(obj.id, obj.id))\n",
    "    \n",
    "            cv2_im = cv2.rectangle(cv2_im, (x0, y0), (x1, y1), (0, 255, 0), 2)\n",
    "            cv2_im = cv2.putText(cv2_im, label, (x0, y0+30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 0, 0), 2)\n",
    "    return cv2_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30699ba-5f32-4159-862a-6385b316a085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Dependencies\n",
    "import IPython\n",
    "import IPython.display\n",
    "from io import BytesIO\n",
    "import PIL.Image\n",
    "\n",
    "# [FUNCTION] Prepare .ipynb display\n",
    "def show_rgb_image_to_display(image_rgb, display):\n",
    "    \"\"\"\n",
    "    Displays a color image in the Jupyter Notebook.\n",
    "    Assumes image is in RGB format.\n",
    "    \"\"\"\n",
    "    io = BytesIO()\n",
    "    image = cv2.cvtColor(image_rgb, cv2.COLOR_BGR2RGB)\n",
    "    PIL.Image.fromarray(image).save(io, 'jpeg')\n",
    "    img_display = IPython.display.Image(data=io.getvalue())\n",
    "    display.update(img_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c02d3c-90dc-4cb2-b5a0-713c5f913fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The actual display\n",
    "display = IPython.display.display('', display_id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b846b9-2c27-40e8-8f01-2407a9baa479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: Load model and labels using pycoral.utils\n",
    "print('Loading {} with {} labels.'.format(model_path, label_path))\n",
    "interpreter = make_interpreter(model_path)\n",
    "interpreter.allocate_tensors()\n",
    "labels = read_label_file(label_path)\n",
    "inference_size = input_size(interpreter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6453442-e52d-4687-af67-bd95d586f61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2: Open webcam\n",
    "cap = cv2.VideoCapture(0) # Default webcam has ID of 0\n",
    "\n",
    "# STEP 3: Loop through webcam camera stream and run model\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read() # Read from webcam\n",
    "    \n",
    "    if frame is None:\n",
    "        break # stop script if frame is empty\n",
    "    else:\n",
    "        \n",
    "        # STEP 4: Preprocess image to the size and shape accepted by model\n",
    "        rgb_image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        rgb_image = cv2.resize(rgb_image, inference_size)\n",
    "\n",
    "        # STEP 5: Let the model do the work\n",
    "        run_inference(interpreter, rgb_image.tobytes())\n",
    "\n",
    "        # STEP 6: Get objects detected from the model\n",
    "        objs = get_objects(interpreter, SCORE_THRESH)[:NUM_CLASSES]\n",
    "\n",
    "        # STEP 7: Label detected objects to frame\n",
    "        image = append_objs_to_img(frame, inference_size, objs, labels)\n",
    "\n",
    "        # STEP 8: Show labeled image to screen\n",
    "        show_rgb_image_to_display(image, display)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fcfc46-a9fe-4ad0-b52c-ae9690bdd7e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
